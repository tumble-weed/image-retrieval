{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "\n",
    "import itertools\n",
    "import sklearn.metrics.pairwise\n",
    "import pickle\n",
    "import torch\n",
    "import torchvision\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tensor_to_numpy = lambda t:t.detach().cpu().numpy()\n",
    "\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "class LFWDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,rootdir,filelist,transform):\n",
    "        super(LFWDataset,self).__init__()\n",
    "        self.filelist = filelist\n",
    "        self.rootdir = rootdir\n",
    "        self.transform = transform\n",
    "    def __getitem__(self,idx):\n",
    "#         import pdb;pdb.set_trace()\n",
    "        fname = os.path.join(self.rootdir,\n",
    "                             self.filelist[idx])\n",
    "        label = self.filelist[idx].split('/')[0]\n",
    "#         import pdb;pdb.set_trace()\n",
    "#         pdb.set_trace()\n",
    "        image = io.imread(fname)\n",
    "        pil_image = Image.fromarray(image)\n",
    "        \n",
    "        tensor_image = self.transform(pil_image)\n",
    "        return tensor_image,label,fname\n",
    "        pass\n",
    "    def __len__(self):\n",
    "        return len(self.filelist)\n",
    "        pass\n",
    "\n",
    "    \n",
    "class LFWClassSampler(torch.utils.data.Sampler):\n",
    "    def __init__(self,\n",
    "                 class_to_idx,\n",
    "                 filelist,\n",
    "                 ):\n",
    "#         super(PKSampler,self).__init__()\n",
    "        self.class_to_idx = class_to_idx\n",
    "        self.classes = list(self.class_to_idx.keys())\n",
    "        self.n_classes = len(self.classes)\n",
    "        \n",
    "        self.filelist = filelist\n",
    "        pass\n",
    "    def __iter__(self):\n",
    "        for c in self.classes:\n",
    "            files = self.class_to_idx[c]\n",
    "            yield files        \n",
    "        pass\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_classes\n",
    "        pass\n",
    "\n",
    "    \n",
    "import shutil,tqdm,gc\n",
    "\n",
    "''' write all the embeddings to disk '''\n",
    "def write_all_embeddings_to_disk(model,\n",
    "                                 val_loader,\n",
    "                                 imsize = (224,224),\n",
    "                                 batch_size = 512,\n",
    "                                 embed_dir='embeddings'):\n",
    "    embed_dir = 'embeddings'\n",
    "    if os.path.exists(embed_dir):\n",
    "        shutil.rmtree(embed_dir)\n",
    "    os.makedirs(embed_dir)\n",
    "\n",
    "    classwise_numel = {}\n",
    "    \n",
    "    dummy = torch.ones(*((1,3) + imsize)).to(device)\n",
    "    dummy_embeds = net(dummy)\n",
    "    embed_len = dummy_embeds.shape[-1]\n",
    "    del dummy_embeds\n",
    "    with torch.no_grad():\n",
    "        for i_,b in enumerate(tqdm.tqdm_notebook(val_loader)):\n",
    "\n",
    "            bx,by,bf = b\n",
    "            ci = np.unique(by)[0]\n",
    "    #         print(ci,)\n",
    "            classwise_numel[ci] = len(bf)\n",
    "            embeds_ci = np.zeros((bx.shape[0],embed_len)).astype(np.float32) \n",
    "            n_batches = (bx.shape[0] + batch_size - 1)//batch_size\n",
    "\n",
    "            for bi_ in range(n_batches):\n",
    "                bxi = bx[bi_*batch_size : (bi_+1)*batch_size]\n",
    "                bxi = bxi.to(device)\n",
    "                embeds_bxi = net(bxi)\n",
    "                embeds_bxi_ = tensor_to_numpy(embeds_bxi)\n",
    "                embeds_ci[bi_*batch_size : (bi_+1)*batch_size,:] = embeds_bxi_\n",
    "                del embeds_bxi,bxi\n",
    "                gc.collect()\n",
    "\n",
    "            filenames_ci = bf\n",
    "    #         import pdb;pdb.set_trace()\n",
    "            embeds_ci_fname = str(ci)+'_embeds.pkl'\n",
    "            embeds_ci_fname = os.path.join(embed_dir,embeds_ci_fname)\n",
    "\n",
    "            with open(embeds_ci_fname,'wb') as f:\n",
    "                pickle.dump(embeds_ci,f)\n",
    "                pickle.dump(filenames_ci,f)\n",
    "    #         break\n",
    "        \n",
    "        \n",
    "    \n",
    "def read_embedding_from_disk(ci,embed_dir):\n",
    "    embeds_ci_fname = str(ci)+'_embeds.pkl'\n",
    "    embeds_ci_fname = os.path.join(embed_dir,embeds_ci_fname)\n",
    "    with open(embeds_ci_fname,'rb') as f:\n",
    "        embeds_ci = pickle.load(f)\n",
    "        filenames_ci = pickle.load(f)\n",
    "    return embeds_ci,filenames_ci\n",
    "\n",
    "\n",
    "def retrieve(embed_dir,\n",
    "             query_classes = ['AJ_Cook','Aaron_Peirsol','Aaron_Sorkin'],\n",
    "             nqueries_per_class = 4,\n",
    "             n_retrieval = 4):\n",
    "    \n",
    "    import sklearn.neighbors\n",
    "\n",
    "    query_idx_per_class = {ci:[] for ci in classes}\n",
    "    all_retrieved = []\n",
    "    all_retrieved_distances = []\n",
    "    filenames_of_queries = []\n",
    "    for c_same in query_classes:\n",
    "        ci = classes.index(c_same)\n",
    "        embed_i, filenames_i = read_embedding_from_disk(c_same,embed_dir)\n",
    "        filenames_i = np.array(filenames_i,dtype=object)\n",
    "\n",
    "        nqueries = min(nqueries_per_class,len(filenames_i)) # the maximum number of queries will be lesses if our class doesnt have too many samples\n",
    "\n",
    "        k = min(n_retrieval,len(filenames_i)) # the retrievals per query will be limited by the number of samples the class has\n",
    "\n",
    "        _i = np.arange(embed_i.shape[0])\n",
    "        query_idx_from_ci = np.random.choice(_i,nqueries,replace=False)\n",
    "        query_idx_per_class[ci] = query_idx_from_ci\n",
    "\n",
    "        query_embeddings = embed_i[query_idx_from_ci]\n",
    "        filenames_of_queries_for_c = filenames_i[query_idx_from_ci]\n",
    "        filenames_of_queries.append(filenames_of_queries_for_c)\n",
    "\n",
    "        over_retrieved = {'idx':np.zeros((nqueries,lfw_sampler.n_classes,k)),\n",
    "                          'dist':np.full((nqueries,lfw_sampler.n_classes,k),np.inf),\n",
    "                          'names':np.zeros((nqueries,lfw_sampler.n_classes,k),dtype=object),} # we will retrieve k results from each class, \n",
    "                                                                                              # then compare among these n_classes*k results to again find the top k\n",
    "                                                                                              # thus we over-retrieve\n",
    "\n",
    "\n",
    "        ''' get the locations of the nearest k here (kd tree?) '''\n",
    "        kdt = sklearn.neighbors.KDTree(embed_i,leaf_size=3) #what is leaf size for?\n",
    "        dist, idx = kdt.query(query_embeddings, k=k) # we are letting the first sample be the query itself\n",
    "\n",
    "        over_retrieved['idx'][:,ci,:],over_retrieved['dist'][:,ci,:],over_retrieved['names'][:,ci,:] = idx,dist,filenames_i[idx]\n",
    "\n",
    "\n",
    "        for c_other in classes:\n",
    "\n",
    "            if c_other == c_same:\n",
    "    #             print(c_same,c_other)\n",
    "                continue\n",
    "            cj = classes.index(c_other)\n",
    "            embed_j,filenames_j = read_embedding_from_disk(c_other,embed_dir)\n",
    "\n",
    "            filenames_j = np.array(filenames_j)\n",
    "            '''\n",
    "            D_ij = sklearn.metrics.pairwise.euclidean_distances(query_embeddings,\n",
    "                                                         embed_j)\n",
    "            '''\n",
    "\n",
    "            ''' get the locations of nearest k here (kd tree?) '''\n",
    "            kdt = sklearn.neighbors.KDTree(embed_j,leaf_size=3)\n",
    "            k_for_cj = min(k,len(filenames_j))\n",
    "            dist, idx = kdt.query(query_embeddings, k=k_for_cj)\n",
    "            over_retrieved['idx'][:,cj,:k_for_cj],over_retrieved['dist'][:,cj,:k_for_cj],over_retrieved['names'][:,cj,:k_for_cj] = idx,dist,filenames_j[idx]\n",
    "            pass\n",
    "\n",
    "\n",
    "        dist_from_query = np.reshape(over_retrieved['dist'],(nqueries,-1)) # nqueries_per_class,(n_classes * k)\n",
    "        nearest_k = np.argsort(dist_from_query,axis=-1)[:,:k] # pick the nearest k (note these indices are in 0 to n_classes*k, and cant directly be used to retrieve )\n",
    "\n",
    "        reshaped_names = np.reshape(over_retrieved['names'],(nqueries,-1)) # for each query see all possible retrieval candidates \n",
    "        retrieved_for_c = [ reshaped_names[qi,nearest_k[qi]] for qi in range(nqueries)] # choose the topk for each query\n",
    "        retrieved_distances_for_c= [dist_from_query[qi,nearest_k[qi]] for qi in range(nqueries)]\n",
    "        all_retrieved.append(retrieved_for_c) # append to global retrieval records\n",
    "        all_retrieved_distances.append(retrieved_distances_for_c)\n",
    "\n",
    "    \n",
    "    return all_retrieved,all_retrieved_distances,filenames_of_queries\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "import skimage.io\n",
    "import skimage.util\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def visualize_retrieval(query_classes,\n",
    "                       all_retrieved,\n",
    "                       all_retrieved_distances,\n",
    "                        filenames_of_queries):\n",
    "    \n",
    "    for ci,c in enumerate(query_classes):\n",
    "\n",
    "        retrieved_for_c = all_retrieved[ci]\n",
    "        retrieved_distances_for_c = all_retrieved_distances[ci]\n",
    "        n_retrieved_for_c = len(retrieved_for_c)\n",
    "        names = np.concatenate((filenames_of_queries[ci][:,None],retrieved_for_c),axis=1)\n",
    "        for qi_ in range(n_retrieved_for_c):\n",
    "\n",
    "            nsubplots = retrieved_for_c[qi_].shape[0] + 1\n",
    "            f,ax=plt.subplots(1,nsubplots)\n",
    "            fname_qi_ = filenames_of_queries[ci][qi_].split('/')[-1]\n",
    "            plt.title(fname_qi_)\n",
    "\n",
    "            for i,imname in enumerate(names[qi_]):\n",
    "                im = skimage.io.imread(imname)\n",
    "\n",
    "                ax[i].imshow(im)\n",
    "                ax[i].set_xticks([])\n",
    "                ax[i].set_yticks([])\n",
    "\n",
    "                if i>0: # the first image is the query\n",
    "                    d = round(retrieved_distances_for_c[qi_][i-1],2)\n",
    "                    ax[i].set_xlabel(str(d))\n",
    "\n",
    "            plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
